/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as serializers from "../index";
import * as Letta from "../../api/index";
import * as core from "../../core";
export declare const LlmConfigModelEndpointType: core.serialization.Schema<serializers.LlmConfigModelEndpointType.Raw, Letta.LlmConfigModelEndpointType>;
export declare namespace LlmConfigModelEndpointType {
    type Raw = "openai" | "anthropic" | "google_ai" | "google_vertex" | "azure" | "groq" | "ollama" | "webui" | "webui-legacy" | "lmstudio" | "lmstudio-legacy" | "lmstudio-chatcompletions" | "llamacpp" | "koboldcpp" | "vllm" | "hugging-face" | "mistral" | "together" | "bedrock" | "deepseek" | "xai";
}
