/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as Letta from "../index";
/**
 * Configuration for Language Model (LLM) connection and generation parameters.
 */
export interface LlmConfig {
    /** LLM model name. */
    model: string;
    /** A human-friendly display name for the model. */
    displayName?: string;
    /** The endpoint type for the model. */
    modelEndpointType: Letta.LlmConfigModelEndpointType;
    /** The endpoint for the model. */
    modelEndpoint?: string;
    /** The provider name for the model. */
    providerName?: string;
    /** The provider category for the model. */
    providerCategory?: Letta.ProviderCategory;
    /** The wrapper for the model. */
    modelWrapper?: string;
    /** The context window size for the model. */
    contextWindow: number;
    /** Puts 'inner_thoughts' as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts. */
    putInnerThoughtsInKwargs?: boolean;
    /** The handle for this config, in the format provider/model-name. */
    handle?: string;
    /** The temperature to use when generating text with the model. A higher temperature will result in more random text. */
    temperature?: number;
    /** The maximum number of tokens to generate. If not set, the model will use its default value. */
    maxTokens?: number;
    /** Whether or not the model should use extended thinking if it is a 'reasoning' style model */
    enableReasoner?: boolean;
    /** The reasoning effort to use when generating text reasoning models */
    reasoningEffort?: Letta.LlmConfigReasoningEffort;
    /** Configurable thinking budget for extended thinking. Used for enable_reasoner and also for Google Vertex models like Gemini 2.5 Flash. Minimum value is 1024 when used with enable_reasoner. */
    maxReasoningTokens?: number;
    /** Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. From OpenAI: Number between -2.0 and 2.0. */
    frequencyPenalty?: number;
    /** The framework compatibility type for the model. */
    compatibilityType?: Letta.LlmConfigCompatibilityType;
    /** Soft control for how verbose model output should be, used for GPT-5 models. */
    verbosity?: Letta.LlmConfigVerbosity;
    /** The cost tier for the model (cloud only). */
    tier?: string;
    /** If set to True, enables parallel tool calling. Defaults to False. */
    parallelToolCalls?: boolean;
}
